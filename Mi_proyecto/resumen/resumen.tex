%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%		                Resumen                       %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\onehalfspacing
\chapter*{Resumen} \label{resumen}
\pagestyle{empty}
\thispagestyle{empty} 

La idea principal del presente proyecto ha sido propuesta por el tutor del proyecto, Francisco Moya Fernández, como tema digno de investigación. Así surge este trabajo de fin de grado, el cual ha sido impartido y desarrollado en el Campus Tecnológico de la Fábrica de Armas de Toledo de la Universidad de Castilla-La Mancha durante el curso 2017-2018. Su título define con claridad el contenido: ``sistema de control visual de equipos''. Básicamente, su finalidad consiste en crear un prototipo basado en hardware y software que juntos, implementen la función de controlar dos equipos distintos por medio de los dos dispositivos HID más comunes (teclado y ratón) mediante un sistema de seguimiento ocular. Los resultados que se persiguen con la investigación tratan de demostrar que el sistema planteado puede llevarse a cabo con una correcta elección del hardware y una buena implementación del software mediante la creación de un prototipo, que cumpla los objetivos fijados, no obstante, para tratarse de un producto apto para su producción y venta, son necesarias algunas mejoras.

Acerca del hardware, se usa un único teclado y ratón y Raspberry Pi como microcontrolador central. Éste se conecta a dos microcontroladores Arduino de modelo Leonardo, cada un conectado a un equipo distinto. Respecto al software, se desarrollan principalmente cinco programas:
\begin{itemize}
    \item ``mk.c'': Recoge y demultiplexa los eventos del teclado y ratón.
    \item ``eye\_detect.cpp'': Detecta la región del rostro y sobre ella, analiza las posibles áreas que contienen los ojos y obtiene la posición de los mismos conocidos como ``eventos oculares''.
    \item ``selector.c'': Determina a qué equipo ceder el control en base a los eventos oculares obtenidos por ``eye\_detect.cpp''.
    \item ``Cliente.c'': Toma la salida de ``selector.c'' para establecer la dirección IP del Arduino al que se le envían los eventos de los periféricos de control obtenidos por ``mk.c''.
    \item ``Servidor\_TCP.ino'': Recibe los datos enviados por Raspberry Pi a través de ``Cliente.c'' y los interpreta como pulsaciones de tecla y movimientos de ratón a través de un mecanismo de simulación.
\end{itemize}

\newpage
\chapter*{Abstract} \label{abstract}
\pagestyle{empty}
\thispagestyle{empty} 

The main idea of the present proyect has been suggested by the tutor of the proyect, Francisco Moya Fernández, as a subject which is worthy of study. This is how this TFG arises, which has been imparted and developed at Campus Tecnológico de la Fábrica de Armas in Toledo University of Universidad de Castilla-La Mancha during 2017-2018 academic years. Its title specifically defines the content: ``Computers visual control system''. Basically, its purpose consits in creating a prototype based in hardware and software whose combination lets implement two diferents computers control by the best known HID devices nowadays (keyboard and mouse), by an eye tracking system. The results that we managed to, try to show that the planned system can be carried out by selecting the correct hardware and a good software implementation by creating a prototype that complies with the proposed objectives, however, so as to talk about a product suitable for its production and sale, some improvements are needed.

About the hardware, we only use a keyboard, a mouse and Raspberry Pi as main microcontroller. This one connects to two Arduino Leonardo model microcontrollers, each of them connects to a different computer. With regard to the software, five programs are developed:

\begin{itemize}
    \item ``mk.c'': Collects and demultiplexs the keyboard and mouse events.
    \item ``eye\_detect.cpp'': Detects the face region and analyses the possible areas which contain the eyes in it and gets its positions known as ``eye events''.
    \item ``selector.c'': Determines which computer takes control to based on the eye events got by ``eye\_detect.cpp''.
    \item ``Cliente.c'': Takes the ``selector.c'' output to set the IP Arduino direction which the control periferic events are sent to and got them by ``mk.c''.
    \item ``Servidor\_TCP.ino'': Receives the data sent by Raspberry Pi through ``Cliente.c'' and interprets them as key presses and mouse movements by a simulation mechanism.
\end{itemize}